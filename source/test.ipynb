{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "from utils.Loader import CXR8Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoE Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardGatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, top_k=2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Dimension of input features.\n",
    "            num_experts (int): Total number of experts.\n",
    "            top_k (int): Maximum number of experts to activate (hard gating).\n",
    "        \"\"\"\n",
    "        super(HardGatingNetwork, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the gating network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n",
    "        \n",
    "        Returns:\n",
    "            selected_experts (torch.Tensor): Binary mask of activated experts (batch_size, num_experts).\n",
    "            expert_weights (torch.Tensor): Normalized weights for the selected experts (batch_size, num_experts).\n",
    "        \"\"\"\n",
    "        logits = self.gate(x)\n",
    "        top_k_values, top_k_indices = torch.topk(logits, self.top_k, dim=1)\n",
    "\n",
    "        mask = torch.zeros_like(logits)\n",
    "        mask.scatter_(1, top_k_indices, 1.0)\n",
    "\n",
    "        sparse_logits = mask * logits \n",
    "        expert_weights = F.softmax(sparse_logits, dim=1) \n",
    "\n",
    "        return mask, expert_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpertCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Placeholder for dynamically calculated in_features\n",
    "        self.fc = None  # Dynamically initialized in forward pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        if self.fc is None:\n",
    "            num_features = x.view(x.size(0), -1).size(1)\n",
    "            self.fc = nn.Linear(num_features, 20).to(x.device)  # Output size is 20\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEModel(nn.Module):\n",
    "    def __init__(self, num_experts):\n",
    "        super(MoEModel, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        \n",
    "        # Experts\n",
    "        self.experts = nn.ModuleList([ExpertCNN() for _ in range(num_experts)])\n",
    "        \n",
    "        # Feature extractor for gating\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # Changed in_channels to 1\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 112 * 112, 128),  # Adjust size based on your input image dimensions\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Gating network\n",
    "        self.gating = HardGatingNetwork(input_dim=128, num_experts=num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from the image for gating\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # Get gating scores\n",
    "        mask, gating_scores = self.gating(features)\n",
    "        \n",
    "        # Top-2 sparsity\n",
    "        topk_values, topk_indices = torch.topk(gating_scores, k=2, dim=-1)\n",
    "        \n",
    "        # Compute outputs for all experts\n",
    "        outputs = torch.stack([self.experts[i](x) for i in range(self.num_experts)], dim=1)\n",
    "        \n",
    "        # Select the outputs of the top-k experts\n",
    "        selected_outputs = outputs.gather(\n",
    "            1, topk_indices.unsqueeze(-1).expand(-1, -1, outputs.size(-1))\n",
    "        )\n",
    "        \n",
    "        # Combine the outputs of the selected experts\n",
    "        combined_output = (selected_outputs * topk_values.unsqueeze(-1)).sum(dim=1)\n",
    "        \n",
    "        return combined_output, gating_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.expanduser(\"~/datasets/CXR8/LongTailCXR/nih-cxr-lt_single-label_train.csv\")\n",
    "train_image_dir = os.path.expanduser(\"~/datasets/CXR8/images/images_001/images/\")\n",
    "test_csv_path = os.path.expanduser(\"~/datasets/CXR8/LongTailCXR/nih-cxr-lt_single-label_test.csv\")\n",
    "train_image_dir = os.path.expanduser(\"~/datasets/CXR8/images/images_001/images/\")\n",
    "batch_size = 32\n",
    "image_scale = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert image to grayscale (1 channel)\n",
    "    transforms.Resize(image_scale),               # Resize images to a uniform size\n",
    "    transforms.ToTensor(),                       # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize for grayscale (mean and std for a single channel)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CXR8Dataset(csv_path=train_csv_path, image_dir=train_image_dir, transform=transform)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataset = CXR8Dataset(csv_path=test_csv_path, image_dir=train_image_dir, transform=transform)\n",
    "test_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the filtered dataset: 2895\n",
      "Batch of images: torch.Size([32, 1, 224, 224])\n",
      "Batch of labels: torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images in the filtered dataset: {len(train_dataset)}\")\n",
    "\n",
    "# Test the DataLoader\n",
    "for images, labels in train_data_loader:\n",
    "    print(f\"Batch of images: {images.shape}\")\n",
    "    print(f\"Batch of labels: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experts = 16\n",
    "model = MoEModel(num_experts=num_experts).to('cuda')\n",
    "num_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.5119, Sparsity: 0.9375\n",
      "Epoch [2/3], Loss: 0.2614, Sparsity: 0.9375\n",
      "Epoch [3/3], Loss: 0.2070, Sparsity: 0.9375\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_sparsity = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, gating_scores = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)  # Multi-label loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate sparsity\n",
    "        sparsity = 1 - (gating_scores.sum(dim=1) / model.num_experts).mean().item()\n",
    "        total_sparsity += sparsity\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / len(train_data_loader)\n",
    "    avg_sparsity = total_sparsity / num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Sparsity: {avg_sparsity:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.59%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_data_loader:\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs, _ = model(images)\n",
    "        \n",
    "        # Apply sigmoid to outputs and threshold at 0.5\n",
    "        predictions = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.numel()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
