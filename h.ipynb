{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "import optuna\n",
    "from joblib import Parallel, delayed\n",
    "from utils.Loader import NEUDataset\n",
    "from utils.Perspectiver import Perspectiver\n",
    "from source.Prototype1 import Prototype1\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import multiprocessing\n",
    "import torch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.restoration import denoise_wavelet\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from scipy.ndimage import maximum_filter, minimum_filter, label, generate_binary_structure\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from scipy.ndimage import label as ndi_label, binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prototype1(num_attention_heads=16).to(\"cuda\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using cuda cores\")\n",
    "    model.cuda()\n",
    "\n",
    "dataset = NEUDataset(set=\"train\", seed=555, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = len(dataset)//2\n",
    "THREADS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    loss_record = []\n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Desempaquetar ignorando 'labels'\n",
    "        for images, _, best_parameters in dataloader:\n",
    "            images = images.to('cuda')\n",
    "            best_parameters = best_parameters.to('cuda')\n",
    "\n",
    "            # Forward: el modelo predice sp y sr\n",
    "            pred_reg = model(images)  # salida de regresión\n",
    "\n",
    "            # Calcular la pérdida de regresión\n",
    "            loss = criterion(pred_reg, best_parameters)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        loss_record.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch + 1}/{EPOCH}], Loss: {avg_loss:.4f}\")\n",
    "    return loss, model\n",
    "\n",
    "loss, model = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)           # Dibuja gráfico de línea\n",
    "plt.title(\"Line Chart\")  # Título del gráfico\n",
    "plt.xlabel(\"Índice\")     # Etiqueta eje x\n",
    "plt.ylabel(\"Valor\")      # Etiqueta eje y\n",
    "plt.show()               # Muestra el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar solo la red neuronal en un archivo .pth\n",
    "#torch.save(model.state_dict(), \"h1.pth\")\n",
    "#print(\"Modelo guardado exitosamente en h1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    image , label, best_parameters = dataset.__getitem__(index=i)\n",
    "    values  = model(image.to(\"cuda\"))\n",
    "\n",
    "    sp = float(values[0][0].detach().cpu().numpy())\n",
    "    sr = float(values[0][1].detach().cpu().numpy())\n",
    "\n",
    "    print(\"sp\", sp)\n",
    "    print(\"sr\", sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
