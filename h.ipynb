{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingfeng/Desktop/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "import optuna\n",
    "from joblib import Parallel, delayed\n",
    "from utils.Loader import NEUDataset\n",
    "from utils.Perspectiver import Perspectiver\n",
    "from source.Prototype1 import Prototype1\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import multiprocessing\n",
    "import torch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.restoration import denoise_wavelet\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from scipy.ndimage import maximum_filter, minimum_filter, label, generate_binary_structure\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from scipy.ndimage import label as ndi_label, binary_dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda cores\n"
     ]
    }
   ],
   "source": [
    "model = Prototype1(num_attention_heads=16)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using cuda cores\")\n",
    "    model.cuda()\n",
    "\n",
    "dataset = NEUDataset(set=\"train\", seed=555, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 512\n",
    "THREADS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1868.8723\n",
      "Epoch [2/10], Loss: 1868.8340\n",
      "Epoch [3/10], Loss: 1868.7948\n",
      "Epoch [4/10], Loss: 1868.7566\n",
      "Epoch [5/10], Loss: 1868.7166\n",
      "Epoch [6/10], Loss: 1868.6747\n",
      "Epoch [7/10], Loss: 1868.6309\n",
      "Epoch [8/10], Loss: 1868.5831\n",
      "Epoch [9/10], Loss: 1868.5320\n",
      "Epoch [10/10], Loss: 1868.4827\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Desempaquetar ignorando 'labels'\n",
    "    for images, _, best_parameters in dataloader:\n",
    "        images = images.to('cuda')\n",
    "        best_parameters = best_parameters.to('cuda')\n",
    "\n",
    "        # Forward: el modelo predice sp y sr\n",
    "        pred_reg = model(images)  # salida de regresión\n",
    "\n",
    "        # Calcular la pérdida de regresión\n",
    "        loss = criterion(pred_reg, best_parameters)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCH}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado exitosamente en h1.pth\n"
     ]
    }
   ],
   "source": [
    "# Guardar solo la red neuronal en un archivo .pth\n",
    "torch.save(model.state_dict(), \"h1.pth\")\n",
    "print(\"Modelo guardado exitosamente en h1.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
